<!DOCTYPE html>
<html>

<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-55V1E709SK"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-55V1E709SK');
  </script>
  <meta charset="utf-8">
  <meta name="description"
    content="Spatial-MLLM: Boosting MLLM Capabilities in Visual-based Spatial Intelligence.">
  <meta name="keywords" content="Spatial-MLLM, Spatial Intelligence, MLLM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Spatial-MLLM: Boosting MLLM Capabilities in Visual-based Spatial Intelligence
  </title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/script.js"></script>

</head>

<body>



  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"><span
                style="color: #48a7b5  ;font-weight: bolder;">Spatial-MLLM</span>: Boosting MLLM Capabilities in Visual-based Spatial Intelligence</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://github.com/diankun-wu/">Diankun Wu</a><sup>1*</sup>,
              </span>
              <span class="author-block">
                <a href="https://liuff19.github.io/">Fangfu Liu</a><sup>1*</sup>,
              </span>
              <span class="author-block">
                <a href="https://github.com/CindyHung20/">Yiâ€‘Hsin Hung</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://duanyueqi.github.io/">Yueqi Duan</a><sup>1â€ </sup>
              </span>
            </div>

          <!-- affiliations -->
          <div class="column is-size-5">
            <sup>1</sup> Tsinghua University&nbsp;
            <sup>*</sup> Equal Contribution&nbsp;
            <sup>â€ </sup> Corresponding Author
          </div>


          <!-- TODO: update paper and video link once upload -->
          <div class="column has-text-centered">
            <!-- <div class="publication-links"> -->
              <!-- PDF Link. -->
              <span class="link-block">
              <a href="https://arxiv.org/pdf/"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                </span>
                <span>Paper</span>
              </a>
              </span>
              <span class="link-block">
              <a href="https://arxiv.org/abs/"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="ai ai-arxiv"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/diankun-wu/Spatial-MLLM"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <!-- Demo Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/liuff19/ReconX"
                  class="external-link button is-normal is-rounded is-dark">
                  <span>ðŸ¤— Demo</span>
                </a>
              </span> -->
            </div>


          <!-- Video Link. -->
          <!-- <span class="link-block">
                  <a href="https://youtu.be/470hul75bSM" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a> -->
          </span>
          <!-- Code Link. -->
          <!-- <span class="link-block">
                  <a href="https://github.com/VITA-Group/Instantsplat"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->
        </div>

      </div>
    </div>
    </div>
    </div>
    </div>
  </section>

<hr>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="https://www.youtube.com/"
                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!-- <video id="teaser" autoplay controls loop playsinline height="100%"> -->
        <!-- <source src="static/myvideos/supp-video.mp4" type="video/mp4" /> -->
      <!-- </video> -->
      <h2 class="subtitle has-text-justified">
        We propose <b>Spatial-MLLM</b>, a method that significantly enhances the visual-based spatial intelligence of existing video MLLMs. As shown, Spatial-MLLM is capable of understanding and reasoning about the underlying scene from video input, achieving state-of-the-art performance across a wide range of tasks.
      </h2>
    </div>
  </div>
</section>
  


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advancements in Multimodal Large Language Models (MLLMs) have significantly enhanced performance on 2D visual tasks. However, improving their spatial intelligence remains a challenge. Existing 3D MLLMs always rely on additional 3D or 2.5D data to incorporate spatial awareness, restricting their utility in scenarios with only 2D inputs, such as images or videos. In this paper, we present <b>Spatial-MLLM</b>, a novel framework for visual-based spatial reasoning from purely 2D observations. Unlike conventional video MLLMs which rely on CLIP-based visual encoders optimized for semantic understanding, our key insight is to unleash the strong structure prior from the feed-forward visual geometry foundation model. Specifically, we propose a dual-encoder architecture: a pretrained 2D visual encoder to extract semantic features, and a spatial encoderâ€”initialized from the backbone of the visual geometry modelâ€”to extract 3D structure features. A connector then integrates both features into unified visual tokens for enhanced spatial understanding. Furthermore, we propose a space-aware frame sampling strategy at inference time, which selects the spatially informative frames of a video sequence, ensuring that even under limited token length, the model focuses on frames critical for spatial reasoning. Beyond architecture improvements, we construct the Spatial-MLLM-120k dataset and train the model on it using supervised fine-tuning and GRPO. Extensive experiments on various real-world datasets demonstrate that our spatial-MLLM achieves state-of-the-art performance in a wide range of visual-based spatial understanding and reasoning tasks.
        </div>
      </div>
    </div>
  </div>
</section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Concurrent Work. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Method Overview</h2>
          <div class="content has-text-justified">
            <img src="./static/images/pipeline-spatialmllm-2.png">

            <p><strong>Overview of Spatial-MLLM</strong>. Our model is composed of a 2D visual encoder, a spatial encoder which is initialized from a feed-forward visual geometry foundation model, a connector, and a large language model backbone. At inference time, we incorporate a space-aware frame sampling strategy to select spatially informative frames when the number of input frames is limited due to GPU memory constraints. </p>

          </div>
        </div>
      </div>
      <!--/ Concurrent Work. -->

    </div>
  </section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Performance</h2>

        <!-- VSIâ€‘Bench -->
        <div class="content has-text-justified">
          <h3 class="title is-5 mb-2 has-text-centered">VSIâ€‘Bench</h3>
          <img src="./static/images/eval_VSIbench.png" alt="VSIâ€‘Bench results">
          <p class="is-size-6">
            <strong>Evaluation Results on VSIâ€‘Bench.</strong>
            For Spatialâ€‘MLLM and Qwenâ€‘2.5&nbsp;VLâ€‘series we use 16â€¯frames as input.
            For other openâ€‘source methods and GPTâ€‘4o, we follow the VSIâ€‘Bench setting and use
            the frame counts specified there (ranging from 8â€¯toâ€¯32â€¯frames).
            For Geminiâ€‘1.5Â Pro, video frames are sampled at&nbsp;1â€¯FPS.
            <strong>Bold</strong> and <u>underline</u> indicate the bestâ€‘performing and
            secondâ€‘bestâ€‘performing openâ€‘source models, respectively.
          </p>
        </div>

        <!-- ScanQA / SQA3D -->
        <div class="content has-text-justified">
          <h3 class="title is-5 mb-2 has-text-centered">ScanQA&nbsp;&amp;&nbsp;SQA3D</h3>
          <img src="./static/images/eval_scanqa_sqa3d.png" alt="ScanQA &amp; SQA3D results">
          <p class="is-size-6">
            <strong>Evaluation Results on ScanQA and SQA3D.</strong>
            We use the validation set of ScanQA and the test set of SQA3D for evaluation, following common practice.
            <strong>Bold</strong> and <u>underline</u> indicate the bestâ€‘performing and
            secondâ€‘bestâ€‘performing models in each model category, respectively.
          </p>
        </div>

      </div><!-- /.column -->
    </div><!-- /.columns -->
  </div><!-- /.container -->
</section>


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Spatial Reasoning Demos</h2>

      <div style="display: flex">
        <div style="display: inline-block; width: 50%; padding-top: 20px; margin-bottom: -20px; text-align: center; font-size: 1.2em;">
          <strong>Spatial Video</strong>
        </div>
        <div style="display: inline-block; width: 50%; padding-top: 20px; margin-bottom: -20px; text-align: center; font-size: 1.2em;">
          <strong>Reasoning and Answering</strong>
        </div>
      </div>

      <div id="results-carousel" class="carousel results-carousel"> 
        <div class="item">
          <div class="item-video" style="display: flex; width: 100%;">
            <video poster="" id="video3" autoplay controls muted loop style="width: 50%; height: auto;">
              <source src="./static/videos/spatial-mllm-examples/sofa-42446151.mp4" type="video/mp4">
            </video>

            <img src="./static/images/sofa-objcnt.png" style="width: 50%; object-fit: contain; height: auto;">
          </div>

          <h2 class="subtitle has-text-centered">
            A cat wearing sunglasses and working as a lifeguard at a pool.
          </h2>
        </div>

        <div class="item">
          <div class="item-video">
            <video poster="" id="video3" autoplay controls muted loop class="video-left">
              <source src="static/videos/flux/a_sheep_and_a_cow.mp4"
              type="video/mp4">
            </video>

            <video poster="" id="video4" autoplay controls muted loop class="video-right">
              <source src="static/videos/flux/a_sheep_and_a_cow_TTS.mp4"
              type="video/mp4">
            </video>
          </div>
          <h2 class="subtitle has-text-centered">
            A sheep and a cow.
          </h2>
        </div>

        <div class="item">
          <div class="item-video">
            <video poster="" id="video3" autoplay controls muted loop class="video-left">
              <source src="static/videos/flux/A_cute_raccoon_playing_guitar_in_a_boat_on_the_ocean.mp4"
              type="video/mp4">
            </video>

            <video poster="" id="video4" autoplay controls muted loop class="video-right">
              <source src="static/videos/flux/A_cute_raccoon_playing_guitar_in_a_boat_on_the_ocean_TTS.mp4"
              type="video/mp4">
            </video>
          </div>
          <h2 class="subtitle has-text-centered">
            A cute raccoon playing guitar in a boat on the ocean.
          </h2>
        </div>

        <div class="item">
          <div class="item-video">
            <video poster="" id="video5" autoplay controls muted loop class="video-left">
              <source src="static/videos/flux/Yellow_flowers_swing_in_the_wind.mp4"
              type="video/mp4">
            </video>
            <video poster="" id="video6" autoplay controls muted loop class="video-right">
              <source src="static/videos/flux/Yellow_flowers_swing_in_the_wind_TTS.mp4"
              type="video/mp4">
            </video>
          </div>
          <h2 class="subtitle has-text-centered">
            Yellow flowers swing in the wind.
          </h2>
        </div>

        <div class="item">
          <div class="item-video">
            <video poster="" id="video5" autoplay controls muted loop class="video-left">
              <source src="static/videos/flux/a_cat_and_a_dog.mp4"
              type="video/mp4">
            </video>
            <video poster="" id="video6" autoplay controls muted loop class="video-right">
              <source src="static/videos/flux/a_cat_and_a_dog_TTS.mp4"
              type="video/mp4">
            </video>
          </div>
          <h2 class="subtitle has-text-centered">
            A cat and a dog.
          </h2>
        </div>

        <div class="item">
          <div class="item-video">
            <video poster="" id="video5" autoplay controls muted loop class="video-left">
              <source src="static/videos/flux/A_storm_trooper_vacuuming_the_beach.mp4"
              type="video/mp4">
            </video>
            <video poster="" id="video6" autoplay controls muted loop class="video-right">
              <source src="static/videos/flux/A_storm_trooper_vacuuming_the_beach_TTS.mp4"
              type="video/mp4">
            </video>
          </div>
          <h2 class="subtitle has-text-centered">
            A storm trooper vacuuming the beach.
          </h2>
        </div>
        
        <div class="item">
          <div class="item-video">
            <video poster="" id="video1" autoplay controls muted loop height="50%" class="video-left">
              <source src="static/videos/flux/A_panda_playing_on_a_swing_set.mp4"
              type="video/mp4">
            </video>
            <video poster="" id="video2" autoplay controls muted loop height="50%" class="video-right">
              <source src="static/videos/flux/A_panda_playing_on_a_swing_set_TTS.mp4"
              type="video/mp4">
            </video>
          </div>
          <h2 class="subtitle has-text-centered">
            A panda playing on a swing set.
          </h2>
        </div>

        <div class="item">
          <div class="item-video">
            <video poster="" id="video1" autoplay controls muted loop height="50%" class="video-left">
              <source src="static/videos/flux/a_zebra_and_a_giraffe.mp4"
              type="video/mp4">
            </video>
            <video poster="" id="video2" autoplay controls muted loop height="50%" class="video-right">
              <source src="static/videos/flux/a_zebra_and_a_giraffe_TTS.mp4"
              type="video/mp4">
            </video>
          </div>
          <h2 class="subtitle has-text-centered">
            A zebra and a giraffe.
          </h2>
        </div>

        <div class="item">
          <div class="item-video">
            <video poster="" id="video1" autoplay controls muted loop height="50%" class="video-left">
              <source src="static/videos/flux/Robot_dancing_in_Times_Square.mp4"
              type="video/mp4">
            </video>
            <video poster="" id="video2" autoplay controls muted loop height="50%" class="video-right">
              <source src="static/videos/flux/Robot_dancing_in_Times_Square_TTS.mp4"
              type="video/mp4">
            </video>
          </div>
          <h2 class="subtitle has-text-centered">
            Robot dancing in Times Square.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>


  <section class="section" id="BibTeX">
   <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{},
      </code></pre>
    </div>
  </section>
  

  <!-- TODO: update the arxiv link and github -->
  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <!-- <a class="icon-link" href="">
          <i class="fas fa-file-pdf"></i>
        </a> -->
        <!-- <a class="icon-link" href="" class="external-link" disabled>
          <i class="fab fa-github"></i> -->
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              We thank the authors of
              We thank the authors of <a href="https://nerfies.github.io/">Nerfies</a> that kindly open sourced the
              template of this website.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>